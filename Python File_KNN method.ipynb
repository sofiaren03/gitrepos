{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Clean the NYC real estate data (AirBnB is already cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from google.colab import files\n",
    "#uploaded = files.upload()\n",
    "\n",
    "realEstateData = pd.read_csv(r'C:\\Users\\Home\\Documents\\Data Mining\\Group Project\\Raw Data\\cost_adjusted_nyc-rolling-sales.csv')\n",
    "\n",
    "## Replace all ' -  's to null and drop the rows\n",
    "# clean1 is realEstateData with values of '-' replaced into NaN\n",
    "clean1 = realEstateData.copy()\n",
    "clean1 = clean1.replace(' -  ', np.nan)\n",
    "\n",
    "# clean2 is clean1 with all rows contains NaN dropped.\n",
    "clean2 = clean1.copy()\n",
    "clean2 = clean2.dropna()\n",
    "\n",
    "# Filter rows with sales price of 100k and more\n",
    "# clean3 is clean2 with sales price of 100k and more\n",
    "clean3 = clean2.copy()\n",
    "clean3['COST ADJUSTED SALE PRICE'] = clean3['COST ADJUSTED SALE PRICE'].apply(pd.to_numeric)\n",
    "clean3 = clean3.loc[clean3['COST ADJUSTED SALE PRICE'] >= 100000]\n",
    "\n",
    "# Filter values in YEAR BUILT anytime after year of 1618\n",
    "# clean4 is clean3 with YEAR BUILT anytime after year of 1618\n",
    "clean4 = clean3.copy()\n",
    "clean4['YEAR BUILT'] = clean4['YEAR BUILT'].apply(pd.to_numeric)\n",
    "clean4 = clean3.loc[clean4['YEAR BUILT'] > 1618]\n",
    "\n",
    "#For Building Class, I have went with the route to filter out all business properties and rental/coops.\n",
    "#A list of values in the Building Class Categories in the underlying data can be found here: \n",
    "#(https://1drv.ms/x/s!Aqw31IAta2jYg89CVfP4UvWRsiuQgg?e=1wBQsh)\n",
    "# Filter all unwanted rows containing certain building classes.\n",
    "# Crop entries in BUILDING CLASS CATEGORY (BCC) and only save first 2 digits as identifying codes.\n",
    "# clean5 is clean4 with clipped BCC values.\n",
    "clean5 = clean4.copy()\n",
    "clean5['BUILDING CLASS CATEGORY'] = clean5['BUILDING CLASS CATEGORY'].astype(str)\n",
    "clean5['BUILDING TYPE CODE'] = clean5['BUILDING CLASS CATEGORY'].str[0:2]\n",
    "clean5['BUILDING TYPE'] = clean5['BUILDING CLASS CATEGORY'].str[2:len(clean5['BUILDING CLASS CATEGORY'])]\n",
    "\n",
    "# Select and save data only with ID code: 01, 02, 03, 04, 12, 13\n",
    "# clean6 is clean5 with only clipped BCC values of 01, 02, 03, 04, 12, 13\n",
    "clean6 = clean5.copy()\n",
    "clean6 = clean6.loc[(clean6['BUILDING TYPE CODE'] == '01') |\n",
    "                    (clean6['BUILDING TYPE CODE'] == '02') |\n",
    "                    (clean6['BUILDING TYPE CODE'] == '03') |\n",
    "                    (clean6['BUILDING TYPE CODE'] == '04') |\n",
    "                    (clean6['BUILDING TYPE CODE'] == '12') |\n",
    "                    (clean6['BUILDING TYPE CODE'] == '13')]\n",
    "\n",
    "#Recoding borough data:\n",
    "# clean7 is clean6 with recoded borough data\n",
    "clean7 = clean6.copy()\n",
    "clean7.reset_index(drop=True,inplace=True)\n",
    "\n",
    "# change data type of borough into string\n",
    "clean7['BOROUGH'] = clean7['BOROUGH'].apply(str)\n",
    "\n",
    "#create BUROUGH NAME empty list for use in loop\n",
    "borough_name = []\n",
    "\n",
    "#Populate borough_name\n",
    "for i in range(len(clean7['BOROUGH'])):\n",
    "    if clean7['BOROUGH'][i] == '1':\n",
    "        borough_name.append('Manhattan')\n",
    "    elif clean7['BOROUGH'][i] == '2':\n",
    "        borough_name.append('Bronx')\n",
    "    elif clean7['BOROUGH'][i] == '3':\n",
    "        borough_name.append('Brooklyn')\n",
    "    elif clean7['BOROUGH'][i] == '4':\n",
    "        borough_name.append('Queens')\n",
    "    elif clean7['BOROUGH'][i] == '5':\n",
    "        borough_name.append('Staten Island')\n",
    "    \n",
    "#make borough_name a new column in the dataframe\n",
    "clean7['BOROUGH NAME'] = borough_name\n",
    "\n",
    "## At this stage, clean7 is the current cleaned database.\n",
    "#Export as csv\n",
    "clean7.to_csv(r'C:\\Users\\Home\\Documents\\Data Mining\\Group Project\\Python Exports\\NYC_Real_Estate_Cleaned.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process several files' data to determine the number of subway stops near each property"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with longitude and latitude on the NYC Subway data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import needed modules and the data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as math\n",
    "stations = pd.read_csv(r'C:\\Users\\Home\\Documents\\Data Mining\\Group Project\\Raw Data\\NYC_Subway_Data.csv')\n",
    "\n",
    "#extract longitude and latitude and rejoin the resulting dataframe with the original\n",
    "stations_2 = stations['the_geom'].str.replace('(','').str.replace(')','').str.split(expand=True).rename(columns={0:'Junk', 1:'Longitude',2:'Latitude'})\n",
    "stations_3 = pd.concat([stations, stations_2],axis= 1)\n",
    "\n",
    "# Convert coordinates to floats and drop the crap columns\n",
    "stations_3['Longitude'] = stations_3['Longitude'].astype('float64')\n",
    "stations_3['Latitude'] = stations_3['Latitude'].astype('float64')\n",
    "stations_4 = stations_3.drop(['URL'], axis = 1).drop(['the_geom'], axis = 1).drop(['Junk'], axis = 1)\n",
    "\n",
    "#Further convert longitude and Latitude to degrees, minutes, and miles\n",
    "\n",
    "#Per information found at http://astro.unl.edu/naap/motion1/tc_units.html#:~:text=Degrees%2C%20Minutes%2C%20Seconds,into%2060%20seconds%20(%E2%80%9D).\n",
    "degrees_to_minutes_convert = 60\n",
    "\n",
    "#Per information found at https://www.usgs.gov/faqs/how-much-distance-does-a-degree-minute-and-second-cover-your-maps?qt-news_science_products=0#qt-news_science_products\n",
    "miles_for_latitude_degree = 69\n",
    "miles_for_latitude_minute = 1.15\n",
    "miles_for_longitude_degree = 54.6\n",
    "miles_for_longitude_minute = .91\n",
    "\n",
    "stations_4['Longitude Degrees'] = np.ceil(stations_4[\"Longitude\"])\n",
    "stations_4['Longitude Minutes'] = (stations_4[\"Longitude\"] - stations_4['Longitude Degrees']) * degrees_to_minutes_convert\n",
    "stations_4['Longitude Miles'] = (stations_4['Longitude Degrees'] * miles_for_longitude_degree) + (stations_4['Longitude Minutes'] * miles_for_longitude_minute)\n",
    "\n",
    "stations_4['Latitude Degrees'] = np.floor(stations_4[\"Latitude\"])\n",
    "stations_4['Latitude Minutes'] = (stations_4[\"Latitude\"] - stations_4['Latitude Degrees']) * degrees_to_minutes_convert\n",
    "stations_4['Latitude Miles'] = (stations_4['Latitude Degrees'] * miles_for_latitude_degree) + (stations_4['Latitude Minutes'] * miles_for_latitude_minute)\n",
    "\n",
    "stations_4.head()\n",
    "\n",
    "#Export file\n",
    "stations_4.to_csv(r'C:\\Users\\Home\\Documents\\Data Mining\\Group Project\\Python Exports\\NYC_Subway_Coordinates.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with longitude and latitude, and finding distance to subway stops, on the AirBnB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import needed modules and the data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as math\n",
    "from datetime import datetime\n",
    "\n",
    "#Please note that in the underlying raw data file, several rows were shifted to the right, causing odd values to appear\n",
    "#in the date column. Python however, thinks that no data is shifted and as such will not recognize anything when I\n",
    "# ask it to drop zeros in the date column. Therefore, I have opted to manually cut down the file to 2016 and 2017 in Excel prior to import\n",
    "airbnb = pd.read_csv(r'C:\\Users\\Home\\Documents\\Data Mining\\Group Project\\Raw Data\\Cost_Adjusted_AirBnB_NYC_2016_and_2017_manually_isolated.csv',encoding = 'unicode_escape')\n",
    "\n",
    "#Convert longitude and Latitude to degrees, minutes, and miles\n",
    "#Per information found at http://astro.unl.edu/naap/motion1/tc_units.html#:~:text=Degrees%2C%20Minutes%2C%20Seconds,into%2060%20seconds%20(%E2%80%9D).\n",
    "degrees_to_minutes_convert = 60\n",
    "\n",
    "#Per information found at https://www.usgs.gov/faqs/how-much-distance-does-a-degree-minute-and-second-cover-your-maps?qt-news_science_products=0#qt-news_science_products\n",
    "miles_for_latitude_degree = 69\n",
    "miles_for_latitude_minute = 1.15\n",
    "miles_for_longitude_degree = 54.6\n",
    "miles_for_longitude_minute = .91\n",
    "\n",
    "airbnb['Longitude Degrees'] = np.ceil(airbnb[\"longitude\"])\n",
    "airbnb['Longitude Minutes'] = (airbnb[\"longitude\"] - airbnb['Longitude Degrees']) * degrees_to_minutes_convert\n",
    "airbnb['Longitude Miles'] = (airbnb['Longitude Degrees'] * miles_for_longitude_degree) + (airbnb['Longitude Minutes'] * miles_for_longitude_minute)\n",
    "\n",
    "airbnb['Latitude Degrees'] = np.floor(airbnb[\"latitude\"])\n",
    "airbnb['Latitude Minutes'] = (airbnb[\"latitude\"] - airbnb['Latitude Degrees']) * degrees_to_minutes_convert\n",
    "airbnb['Latitude Miles'] = (airbnb['Latitude Degrees'] * miles_for_latitude_degree) + (airbnb['Latitude Minutes'] * miles_for_latitude_minute)\n",
    "\n",
    "#Clean data a little bit more by dropping now needless longitude and latitude measures and renaming some columns\n",
    "airbnb.drop(['Longitude Degrees','Longitude Minutes','Latitude Degrees','Latitude Minutes'],axis=1,inplace=True)\n",
    "airbnb.rename(columns={\"Longitude Miles\":\"Airbnb Longitude Miles\",\"Latitude Miles\":\"Airbnb Latitude Miles\"},inplace=True)\n",
    "\n",
    "airbnb.reset_index(drop=True, inplace = True)\n",
    "\n",
    "#Now, we attempt Python Magic! For every Airbnb property entry, take its longitude and latitude in miles, which is just a coordinate point on the globe,\n",
    "#and find the distance, using the distance formula, to every subway stop. Then, count the number of stops within a specified\n",
    "#\"arbitrary mile radius\" and deposit that count next to the Airbnb property\n",
    "\n",
    "arbitrary_mile_radius = .622 #This is equal to one kilometer\n",
    "success_count_list = []\n",
    "\n",
    "for i in range(len(airbnb['Airbnb Longitude Miles'])):\n",
    "    success_count = 0\n",
    "    for j in range(len(stations_4['Longitude Miles'])):  \n",
    "        #This next line is the distance formula: square root of ((x2 - x1)^2 + (y2 - y1)^2)\n",
    "        if math.sqrt((airbnb.at[i,'Airbnb Longitude Miles'] - stations_4.at[j,'Longitude Miles'])**2 + (airbnb.at[i,'Airbnb Latitude Miles'] - stations_4.at[j,'Latitude Miles'])**2) < arbitrary_mile_radius:\n",
    "            success_count += 1\n",
    "    success_count_list.append(success_count)\n",
    "\n",
    "airbnb['Number of Subway Stops Near Each AirBnB Property'] = success_count_list\n",
    "\n",
    "airbnb.head()\n",
    "\n",
    "airbnb.to_csv(r'C:\\Users\\Home\\Documents\\Data Mining\\Group Project\\Python Exports\\AirBnB_With_Subway_Stops.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with longitude and latitude, and finding distance to subway stops, on the NYC Real Estate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import needed modules and the data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as math\n",
    "from datetime import datetime\n",
    "\n",
    "zip_code_coordinates = pd.read_csv(r'C:\\Users\\Home\\Documents\\Data Mining\\Group Project\\Raw Data\\zip_code_coordinates.csv')\n",
    "NYC_real_estate = pd.read_csv(r'C:\\Users\\Home\\Documents\\Data Mining\\Group Project\\Python Exports\\NYC_Real_Estate_Cleaned.csv')\n",
    "\n",
    "#renaming Zip Code column as \"ZIP\" in NYC data set in order to synchronize with the zip codes data set\n",
    "NYC_real_estate.rename(columns={\"ZIP CODE\":\"ZIP\"},inplace=True)\n",
    "\n",
    "#merging NYC data with zip code data so that each zip code in the NYC data gets a longitude and latitude\n",
    "NYC_real_estate_with_zip_codes = NYC_real_estate.merge(zip_code_coordinates,on = \"ZIP\")\n",
    "\n",
    "#Convert longitude and Latitude to degrees, minutes, and miles (reproduced below from above only for reference)\n",
    "#Per information found at http://astro.unl.edu/naap/motion1/tc_units.html#:~:text=Degrees%2C%20Minutes%2C%20Seconds,into%2060%20seconds%20(%E2%80%9D).\n",
    "#degrees_to_minutes_convert = 60\n",
    "\n",
    "#Per information found at https://www.usgs.gov/faqs/how-much-distance-does-a-degree-minute-and-second-cover-your-maps?qt-news_science_products=0#qt-news_science_products\n",
    "#(reproduced below from above only for reference)\n",
    "#miles_for_latitude_degree = 69\n",
    "#miles_for_latitude_minute = 1.15\n",
    "#miles_for_longitude_degree = 54.6\n",
    "#miles_for_longitude_minute = .91\n",
    "\n",
    "NYC_real_estate_with_zip_codes['Longitude Degrees'] = np.ceil(NYC_real_estate_with_zip_codes[\"LNG\"])\n",
    "NYC_real_estate_with_zip_codes['Longitude Minutes'] = (NYC_real_estate_with_zip_codes[\"LNG\"] - NYC_real_estate_with_zip_codes['Longitude Degrees']) * degrees_to_minutes_convert\n",
    "NYC_real_estate_with_zip_codes['Longitude Miles'] = (NYC_real_estate_with_zip_codes['Longitude Degrees'] * miles_for_longitude_degree) + (NYC_real_estate_with_zip_codes['Longitude Minutes'] * miles_for_longitude_minute)\n",
    "\n",
    "NYC_real_estate_with_zip_codes['Latitude Degrees'] = np.floor(NYC_real_estate_with_zip_codes[\"LAT\"])\n",
    "NYC_real_estate_with_zip_codes['Latitude Minutes'] = (NYC_real_estate_with_zip_codes[\"LAT\"] - NYC_real_estate_with_zip_codes['Latitude Degrees']) * degrees_to_minutes_convert\n",
    "NYC_real_estate_with_zip_codes['Latitude Miles'] = (NYC_real_estate_with_zip_codes['Latitude Degrees'] * miles_for_latitude_degree) + (NYC_real_estate_with_zip_codes['Latitude Minutes'] * miles_for_latitude_minute)\n",
    "\n",
    "#Clean data a little bit more by dropping now needless longitude and latitude measures and renaming some columns\n",
    "NYC_real_estate_with_zip_codes.drop(['Unnamed: 0','Longitude Degrees','Longitude Minutes','Latitude Degrees','Latitude Minutes','EASE-MENT'],axis=1,inplace=True)\n",
    "NYC_real_estate_with_zip_codes.rename(columns={\"Longitude Miles\":\"NYC Real Estate Longitude Miles\",\"Latitude Miles\":\"NYC Real Estate Latitude Miles\"},inplace=True)\n",
    "\n",
    "NYC_real_estate_with_zip_codes = NYC_real_estate_with_zip_codes.reset_index(drop=True)\n",
    "\n",
    "#Now, we attempt Python Magic! Again! For every Airbnb property entry, take its longitude and latitude in miles, which is just a coordinate point on the globe,\n",
    "#and find the distance, using the distance formula, to every subway stop. Then, count the number of stops within a specified\n",
    "#\"arbitrary mile radius\" and deposit that count next to the NYC property\n",
    "\n",
    "arbitrary_mile_radius_2 = .622 #This is equal to one kilometer\n",
    "success_count_list_2 = []\n",
    "\n",
    "for i in range(len(NYC_real_estate_with_zip_codes['NYC Real Estate Longitude Miles'])):\n",
    "    success_count_2 = 0\n",
    "    for j in range(len(stations_4['Longitude Miles'])):  \n",
    "        #This next line is the distance formula: square root of ((x2 - x1)^2 + (y2 - y1)^2)\n",
    "        if math.sqrt((NYC_real_estate_with_zip_codes.at[i,'NYC Real Estate Longitude Miles'] - stations_4.at[j,'Longitude Miles'])**2 + (NYC_real_estate_with_zip_codes.at[i,'NYC Real Estate Latitude Miles'] - stations_4.at[j,'Latitude Miles'])**2) < arbitrary_mile_radius_2:\n",
    "            success_count_2 += 1\n",
    "    success_count_list_2.append(success_count_2)\n",
    "\n",
    "NYC_real_estate_with_zip_codes['Number of Subway Stops Near Each Property'] = success_count_list_2\n",
    "\n",
    "NYC_real_estate_with_zip_codes.head()\n",
    "\n",
    "NYC_real_estate_with_zip_codes.to_csv(r'C:\\Users\\Home\\Documents\\Data Mining\\Group Project\\Python Exports\\NYC_Real_Estate_With_Subway_Stops.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data setup, numerical standardization, and dummy coding for AirBnB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>Gross Income from property per listing</th>\n",
       "      <th>Number of Subway Stops Near Each AirBnB Property</th>\n",
       "      <th>neighbourhood_group_Bronx</th>\n",
       "      <th>neighbourhood_group_Brooklyn</th>\n",
       "      <th>neighbourhood_group_Manhattan</th>\n",
       "      <th>neighbourhood_group_Queens</th>\n",
       "      <th>neighbourhood_group_Staten Island</th>\n",
       "      <th>room_type_Entire home/apt</th>\n",
       "      <th>room_type_Private room</th>\n",
       "      <th>room_type_Shared room</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.402097</td>\n",
       "      <td>0.876339</td>\n",
       "      <td>-0.277178</td>\n",
       "      <td>0.083653</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.262722</td>\n",
       "      <td>3.167154</td>\n",
       "      <td>-0.213674</td>\n",
       "      <td>-0.149094</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.233058</td>\n",
       "      <td>1.225785</td>\n",
       "      <td>0.023643</td>\n",
       "      <td>0.549148</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.200749</td>\n",
       "      <td>-0.288483</td>\n",
       "      <td>-0.093345</td>\n",
       "      <td>-1.312829</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.047141</td>\n",
       "      <td>0.216273</td>\n",
       "      <td>-0.293879</td>\n",
       "      <td>-0.149094</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   minimum_nights  reviews_per_month  Gross Income from property per listing  \\\n",
       "0        2.402097           0.876339                               -0.277178   \n",
       "1       -0.262722           3.167154                               -0.213674   \n",
       "2        0.233058           1.225785                                0.023643   \n",
       "3       -0.200749          -0.288483                               -0.093345   \n",
       "4        0.047141           0.216273                               -0.293879   \n",
       "\n",
       "   Number of Subway Stops Near Each AirBnB Property  \\\n",
       "0                                          0.083653   \n",
       "1                                         -0.149094   \n",
       "2                                          0.549148   \n",
       "3                                         -1.312829   \n",
       "4                                         -0.149094   \n",
       "\n",
       "   neighbourhood_group_Bronx  neighbourhood_group_Brooklyn  \\\n",
       "0                          0                             1   \n",
       "1                          0                             0   \n",
       "2                          0                             0   \n",
       "3                          0                             1   \n",
       "4                          0                             1   \n",
       "\n",
       "   neighbourhood_group_Manhattan  neighbourhood_group_Queens  \\\n",
       "0                              0                           0   \n",
       "1                              1                           0   \n",
       "2                              1                           0   \n",
       "3                              0                           0   \n",
       "4                              0                           0   \n",
       "\n",
       "   neighbourhood_group_Staten Island  room_type_Entire home/apt  \\\n",
       "0                                  0                          0   \n",
       "1                                  0                          0   \n",
       "2                                  0                          1   \n",
       "3                                  0                          1   \n",
       "4                                  0                          0   \n",
       "\n",
       "   room_type_Private room  room_type_Shared room  \n",
       "0                       1                      0  \n",
       "1                       1                      0  \n",
       "2                       0                      0  \n",
       "3                       0                      0  \n",
       "4                       1                      0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import Needed Packages\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statistics as stat\n",
    "from sklearn import metrics\n",
    "\n",
    "#read in the data\n",
    "df_airbnb = pd.read_csv(r'C:\\Users\\Home\\Documents\\Data Mining\\Group Project\\Python Exports\\AirBnB_With_Subway_Stops.csv')\n",
    "\n",
    "#drop the single dependent variable observation where the price = 0\n",
    "df_airbnb.drop(df_airbnb[df_airbnb['price'] == 0].index, inplace = True)\n",
    "\n",
    "#drop unneeded columns\n",
    "df_airbnb.drop(['Cost percentage per listing','price','id','name','host_id','host_name','neighbourhood','latitude','longitude','last_review','calculated_host_listings_count', \n",
    "        'availability_365','Airbnb Longitude Miles','Airbnb Latitude Miles','number_of_reviews'],axis=1, inplace=True)\n",
    "\n",
    "#Group variables into a list based on type\n",
    "cvar_list_airbnb = ['neighbourhood_group','room_type']\n",
    "nvar_list_airbnb = ['Gross Income from property per listing','minimum_nights','reviews_per_month','Number of Subway Stops Near Each AirBnB Property']\n",
    "\n",
    "#standardizing numerical values for use in model\n",
    "standardized_data_airbnb = df_airbnb.copy()\n",
    "\n",
    "original_column_values_airbnb = df_airbnb[nvar_list_airbnb]\n",
    "sample_mean_airbnb = df_airbnb[nvar_list_airbnb].mean()\n",
    "sample_stddev_airbnb = df_airbnb[nvar_list_airbnb].std()\n",
    "\n",
    "standardized_data_airbnb[nvar_list_airbnb] = standardized_data_airbnb[nvar_list_airbnb].astype('float64')\n",
    "\n",
    "standardized_data_airbnb[nvar_list_airbnb] = ((original_column_values_airbnb - sample_mean_airbnb)/sample_stddev_airbnb)\n",
    "\n",
    "#Creating Dummies for Categorical Variables\n",
    "standardized_data_airbnb[cvar_list_airbnb] = standardized_data_airbnb[cvar_list_airbnb].astype('category')\n",
    "standardized_data_airbnb = pd.get_dummies(standardized_data_airbnb, prefix_sep = '_')\n",
    "\n",
    "df2_airbnb = standardized_data_airbnb.copy()\n",
    "\n",
    "#Data Partition:\n",
    "#Splitting the data into our partitions will return two dataframes, so we must prep like so:\n",
    "testpart_size_airbnb = .2\n",
    "df_partition_airbnb = df2_airbnb.copy()\n",
    "\n",
    "df_nontestdata_airbnb, df_testdata_airbnb = train_test_split(df_partition_airbnb, test_size = testpart_size_airbnb, random_state = 1)\n",
    "df2_airbnb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data setup, numerical standardization, and dummy coding for NYC Real Estate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RESIDENTIAL UNITS</th>\n",
       "      <th>COMMERCIAL UNITS</th>\n",
       "      <th>LAND SQUARE FEET</th>\n",
       "      <th>GROSS SQUARE FEET</th>\n",
       "      <th>YEAR BUILT</th>\n",
       "      <th>COST ADJUSTED SALE PRICE</th>\n",
       "      <th>Number of Subway Stops Near Each Property</th>\n",
       "      <th>TAX CLASS AT TIME OF SALE_1</th>\n",
       "      <th>TAX CLASS AT TIME OF SALE_2</th>\n",
       "      <th>BUILDING TYPE_ CONDOS - ELEVATOR APARTMENTS</th>\n",
       "      <th>BUILDING TYPE_ CONDOS - WALKUP APARTMENTS</th>\n",
       "      <th>BUILDING TYPE_ ONE FAMILY DWELLINGS</th>\n",
       "      <th>BUILDING TYPE_ TAX CLASS 1 CONDOS</th>\n",
       "      <th>BUILDING TYPE_ THREE FAMILY DWELLINGS</th>\n",
       "      <th>BUILDING TYPE_ TWO FAMILY DWELLINGS</th>\n",
       "      <th>BOROUGH NAME_Bronx</th>\n",
       "      <th>BOROUGH NAME_Brooklyn</th>\n",
       "      <th>BOROUGH NAME_Manhattan</th>\n",
       "      <th>BOROUGH NAME_Queens</th>\n",
       "      <th>BOROUGH NAME_Staten Island</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.821079</td>\n",
       "      <td>-0.157310</td>\n",
       "      <td>-0.392310</td>\n",
       "      <td>2.205567</td>\n",
       "      <td>-1.305068</td>\n",
       "      <td>6.614819</td>\n",
       "      <td>3.657612</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.715302</td>\n",
       "      <td>6.219301</td>\n",
       "      <td>-0.307208</td>\n",
       "      <td>3.386482</td>\n",
       "      <td>-0.750944</td>\n",
       "      <td>6.939435</td>\n",
       "      <td>3.657612</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.251683</td>\n",
       "      <td>-0.157310</td>\n",
       "      <td>-0.152080</td>\n",
       "      <td>2.068863</td>\n",
       "      <td>-1.305068</td>\n",
       "      <td>7.488786</td>\n",
       "      <td>3.657612</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.821079</td>\n",
       "      <td>-0.157310</td>\n",
       "      <td>-0.313043</td>\n",
       "      <td>5.512760</td>\n",
       "      <td>-1.334232</td>\n",
       "      <td>19.824210</td>\n",
       "      <td>3.657612</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.821079</td>\n",
       "      <td>6.219301</td>\n",
       "      <td>-0.338817</td>\n",
       "      <td>2.871212</td>\n",
       "      <td>-1.363397</td>\n",
       "      <td>10.984655</td>\n",
       "      <td>3.657612</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RESIDENTIAL UNITS  COMMERCIAL UNITS  LAND SQUARE FEET  GROSS SQUARE FEET  \\\n",
       "0          -0.821079         -0.157310         -0.392310           2.205567   \n",
       "1           0.715302          6.219301         -0.307208           3.386482   \n",
       "2           2.251683         -0.157310         -0.152080           2.068863   \n",
       "3          -0.821079         -0.157310         -0.313043           5.512760   \n",
       "4          -0.821079          6.219301         -0.338817           2.871212   \n",
       "\n",
       "   YEAR BUILT  COST ADJUSTED SALE PRICE  \\\n",
       "0   -1.305068                  6.614819   \n",
       "1   -0.750944                  6.939435   \n",
       "2   -1.305068                  7.488786   \n",
       "3   -1.334232                 19.824210   \n",
       "4   -1.363397                 10.984655   \n",
       "\n",
       "   Number of Subway Stops Near Each Property  TAX CLASS AT TIME OF SALE_1  \\\n",
       "0                                   3.657612                            1   \n",
       "1                                   3.657612                            1   \n",
       "2                                   3.657612                            1   \n",
       "3                                   3.657612                            1   \n",
       "4                                   3.657612                            1   \n",
       "\n",
       "   TAX CLASS AT TIME OF SALE_2  \\\n",
       "0                            0   \n",
       "1                            0   \n",
       "2                            0   \n",
       "3                            0   \n",
       "4                            0   \n",
       "\n",
       "   BUILDING TYPE_ CONDOS - ELEVATOR APARTMENTS              \\\n",
       "0                                                  0         \n",
       "1                                                  0         \n",
       "2                                                  0         \n",
       "3                                                  0         \n",
       "4                                                  0         \n",
       "\n",
       "   BUILDING TYPE_ CONDOS - WALKUP APARTMENTS                \\\n",
       "0                                                  0         \n",
       "1                                                  0         \n",
       "2                                                  0         \n",
       "3                                                  0         \n",
       "4                                                  0         \n",
       "\n",
       "   BUILDING TYPE_ ONE FAMILY DWELLINGS                      \\\n",
       "0                                                  1         \n",
       "1                                                  0         \n",
       "2                                                  0         \n",
       "3                                                  1         \n",
       "4                                                  1         \n",
       "\n",
       "   BUILDING TYPE_ TAX CLASS 1 CONDOS                        \\\n",
       "0                                                  0         \n",
       "1                                                  0         \n",
       "2                                                  0         \n",
       "3                                                  0         \n",
       "4                                                  0         \n",
       "\n",
       "   BUILDING TYPE_ THREE FAMILY DWELLINGS                    \\\n",
       "0                                                  0         \n",
       "1                                                  0         \n",
       "2                                                  1         \n",
       "3                                                  0         \n",
       "4                                                  0         \n",
       "\n",
       "   BUILDING TYPE_ TWO FAMILY DWELLINGS                      \\\n",
       "0                                                  0         \n",
       "1                                                  1         \n",
       "2                                                  0         \n",
       "3                                                  0         \n",
       "4                                                  0         \n",
       "\n",
       "   BOROUGH NAME_Bronx  BOROUGH NAME_Brooklyn  BOROUGH NAME_Manhattan  \\\n",
       "0                   0                      0                       1   \n",
       "1                   0                      0                       1   \n",
       "2                   0                      0                       1   \n",
       "3                   0                      0                       1   \n",
       "4                   0                      0                       1   \n",
       "\n",
       "   BOROUGH NAME_Queens  BOROUGH NAME_Staten Island  \n",
       "0                    0                           0  \n",
       "1                    0                           0  \n",
       "2                    0                           0  \n",
       "3                    0                           0  \n",
       "4                    0                           0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import Needed Packages\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statistics as stat\n",
    "from sklearn import metrics\n",
    "\n",
    "#read in the data\n",
    "df_nyc = pd.read_csv(r'C:\\Users\\Home\\Documents\\Data Mining\\Group Project\\Python Exports\\NYC_Real_Estate_With_Subway_Stops.csv')\n",
    "\n",
    "#drop unneeded columns\n",
    "df_nyc.drop(['BOROUGH','NEIGHBORHOOD','BUILDING CLASS CATEGORY','TAX CLASS AT PRESENT','BLOCK','LOT',\n",
    "             'BUILDING CLASS AT PRESENT','ADDRESS','APARTMENT NUMBER','ZIP', \n",
    "            'TOTAL UNITS','BUILDING CLASS AT TIME OF SALE','SALE DATE','LAT','LNG','NYC Real Estate Longitude Miles',\n",
    "             'NYC Real Estate Latitude Miles','BUILDING TYPE CODE','SALE PRICE','COST %'],axis=1, inplace=True)\n",
    "\n",
    "#Group variables into a list based on type\n",
    "cvar_list_nyc = ['TAX CLASS AT TIME OF SALE','BUILDING TYPE','BOROUGH NAME']\n",
    "nvar_list_nyc = ['COST ADJUSTED SALE PRICE','RESIDENTIAL UNITS','COMMERCIAL UNITS','LAND SQUARE FEET','GROSS SQUARE FEET',\n",
    "                 'YEAR BUILT','Number of Subway Stops Near Each Property']\n",
    "\n",
    "#standardizing numerical values for use in model\n",
    "standardized_data_nyc = df_nyc.copy()\n",
    "\n",
    "original_column_values_nyc = df_nyc[nvar_list_nyc]\n",
    "sample_mean_nyc = df_nyc[nvar_list_nyc].mean()\n",
    "sample_stddev_nyc = df_nyc[nvar_list_nyc].std()\n",
    "\n",
    "standardized_data_nyc[nvar_list_nyc] = ((original_column_values_nyc - sample_mean_nyc)/sample_stddev_nyc)\n",
    "\n",
    "standardized_data_nyc[nvar_list_nyc] = standardized_data_nyc[nvar_list_nyc].astype('float64')\n",
    "\n",
    "#Creating Dummies for Categorical Variables\n",
    "standardized_data_nyc[cvar_list_nyc] = standardized_data_nyc[cvar_list_nyc].astype('category')\n",
    "standardized_data_nyc = pd.get_dummies(standardized_data_nyc, prefix_sep = '_')\n",
    "\n",
    "df2_nyc = standardized_data_nyc.copy()\n",
    "\n",
    "#Data Partition:\n",
    "#Splitting the data into our partitions will return two dataframes, so we must prep like so:\n",
    "testpart_size_nyc = .2\n",
    "df_partition_nyc = df2_nyc.copy()\n",
    "\n",
    "df_nontestdata_nyc, df_testdata_nyc = train_test_split(df_partition_nyc, test_size = testpart_size_nyc, random_state = 1)\n",
    "df2_nyc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN for NYC Real Estate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The optimal k over the validation partition is 9\n",
      "The ASE over the 5 fold validation partition is 0.40385065314919877\n",
      "\n",
      " The optimal k over the test partition is 4\n",
      "The ASE over the 5 fold test partition is 0.2627613241939576\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Separate the predictor values and the DV values into X and y respectively\n",
    "# Placeholder variable: DV\n",
    "DV = 'COST ADJUSTED SALE PRICE'\n",
    "y_nyc = df_nontestdata_nyc[DV]\n",
    "x_nyc = df_nontestdata_nyc.drop(columns=[DV])\n",
    "\n",
    "y_nyc2 = df_testdata_nyc[DV]\n",
    "x_nyc2 = df_testdata_nyc.drop(columns = [DV])\n",
    "\n",
    "# Run Nearest Neighbors with k-fold cross validation with k=5\n",
    "# Placeholder variable: kfolds\n",
    "kfolds = 5\n",
    "\n",
    "# Here we specify within which range of Ks we will search through\n",
    "max_k = 200\n",
    "param_grid = {'n_neighbors': list(range(1, max_k+1))}\n",
    "\n",
    "############ Nearest Neighbors Over the Validation Partition: Run model and find optimal k ######################\n",
    "gridsearch = GridSearchCV(KNeighborsRegressor(metric = 'euclidean'), param_grid, cv=kfolds, n_jobs=-1)\n",
    "gridsearch.fit(x_nyc,y_nyc)\n",
    "clf_bestKNN = gridsearch.best_estimator_\n",
    "optimal_k = clf_bestKNN.n_neighbors\n",
    "\n",
    "#ASE over the validation partition\n",
    "y_nyc_nontest_predicted_CV = clf_bestKNN.predict(x_nyc)\n",
    "n_obs_nontest_CV = df_nontestdata_nyc.shape[0]\n",
    "\n",
    "ASE_nontest_CV = sum((y_nyc - y_nyc_nontest_predicted_CV)**2)/n_obs_nontest_CV\n",
    "print('\\n','The optimal k over the validation partition is',optimal_k)\n",
    "print (\"The ASE over the\",kfolds,\"fold validation partition is\",ASE_nontest_CV)\n",
    "\n",
    "############ Nearest Neighbors Over the Test Partition: Run model and find optimal k ######################\n",
    "gridsearch2 = GridSearchCV(KNeighborsRegressor(metric = 'euclidean'), param_grid, cv=kfolds, n_jobs=-1)\n",
    "gridsearch2.fit(x_nyc2,y_nyc2)\n",
    "clf_bestKNN2 = gridsearch2.best_estimator_\n",
    "optimal_k2 = clf_bestKNN2.n_neighbors\n",
    "\n",
    "#ASE over the test partition\n",
    "y_nyc_test_predicted_CV = clf_bestKNN2.predict(x_nyc2)\n",
    "n_obs_test_CV = df_testdata_nyc.shape[0]\n",
    "\n",
    "ASE_test_CV = sum((y_nyc2 - y_nyc_test_predicted_CV)**2)/n_obs_test_CV\n",
    "print('\\n','The optimal k over the test partition is',optimal_k2)\n",
    "print (\"The ASE over the\",kfolds,\"fold test partition is\",ASE_test_CV)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN for AirBnB Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The optimal k over the validation partition is 168\n",
      "The ASE over the 5 fold validation partition is 0.7574999902115507\n",
      "\n",
      " The optimal k over the test partition is 200\n",
      "The ASE over the 5 fold test partition is 1.7693450762494152\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Separate the predictor values and the DV values into X and y respectively\n",
    "# Placeholder variable: DV\n",
    "DV = 'Gross Income from property per listing'\n",
    "y_airbnb = df_nontestdata_airbnb[DV]\n",
    "x_airbnb = df_nontestdata_airbnb.drop(columns=[DV])\n",
    "\n",
    "y_airbnb2 = df_testdata_airbnb[DV]\n",
    "x_airbnb2 = df_testdata_airbnb.drop(columns = [DV])\n",
    "\n",
    "# Run Nearest Neighbors with k-fold cross validation with k=5\n",
    "# Placeholder variable: kfolds\n",
    "kfolds = 5\n",
    "\n",
    "# Here we specify within which range of Ks we will search through\n",
    "max_k = 200\n",
    "param_grid = {'n_neighbors': list(range(1, max_k+1))}\n",
    "\n",
    "############ Nearest Neighbors Over the Validation Partition: Run model and find optimal k ######################\n",
    "gridsearch = GridSearchCV(KNeighborsRegressor(metric = 'euclidean'), param_grid, cv=kfolds, n_jobs=-1)\n",
    "gridsearch.fit(x_airbnb,y_airbnb)\n",
    "clf_bestKNN = gridsearch.best_estimator_\n",
    "optimal_k = clf_bestKNN.n_neighbors\n",
    "\n",
    "#ASE over the validation partition\n",
    "y_airbnb_nontest_predicted_CV = clf_bestKNN.predict(x_airbnb)\n",
    "n_obs_nontest_CV = df_nontestdata_airbnb.shape[0]\n",
    "\n",
    "ASE_nontest_CV = sum((y_airbnb - y_airbnb_nontest_predicted_CV)**2)/n_obs_nontest_CV\n",
    "print('\\n','The optimal k over the validation partition is',optimal_k)\n",
    "print (\"The ASE over the\",kfolds,\"fold validation partition is\",ASE_nontest_CV)\n",
    "\n",
    "############ Nearest Neighbors Over the Test Partition: Run model and find optimal k ######################\n",
    "gridsearch2 = GridSearchCV(KNeighborsRegressor(metric = 'euclidean'), param_grid, cv=kfolds, n_jobs=-1)\n",
    "gridsearch2.fit(x_airbnb2,y_airbnb2)\n",
    "clf_bestKNN2 = gridsearch2.best_estimator_\n",
    "optimal_k2 = clf_bestKNN2.n_neighbors\n",
    "\n",
    "#ASE over the test partition\n",
    "y_airbnb_test_predicted_CV = clf_bestKNN2.predict(x_airbnb2)\n",
    "n_obs_test_CV = df_testdata_airbnb.shape[0]\n",
    "\n",
    "ASE_test_CV = sum((y_airbnb2 - y_airbnb_test_predicted_CV)**2)/n_obs_test_CV\n",
    "print('\\n','The optimal k over the test partition is',optimal_k2)\n",
    "print (\"The ASE over the\",kfolds,\"fold test partition is\",ASE_test_CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Price of New (Meaning A Tiny Subset of historical) NYC Real Estate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3448472.48   8841657.31   9480472.705  5653233.575  8841657.31\n",
      "  532675.9325  322957.925   440499.9625  262083.9075  349822.0925\n",
      "  274521.0225  956527.12    956527.12    956527.12   1085420.845\n",
      "  563672.615   754141.36    508414.0625  620951.1775  816326.9275\n",
      "  594561.8825  465374.19    677483.51    503906.6275  340098.5325\n",
      "  496693.1025]\n"
     ]
    }
   ],
   "source": [
    "# Load the new made-up NYC Real Estate data\n",
    "df_newdata_nyc = pd.read_csv(r'C:\\Users\\Home\\Documents\\Data Mining\\Group Project\\Raw Data\\NYC_Real_Estate_With_Subway_Stops_Fake_New_Data.csv')\n",
    "\n",
    "# Generate the numerical predictor list\n",
    "npredictor_list_nyc = nvar_list_nyc.copy()\n",
    "npredictor_list_nyc.remove(DV)\n",
    "\n",
    "# Set the datatypes of the variables in the made-up data and drop the dependent variable (since we would not know it in real future data)\n",
    "df_newdata_nyc2 = df_newdata_nyc.copy()\n",
    "df_newdata_nyc2[cvar_list_nyc] = df_newdata_nyc[cvar_list_nyc].astype('category')\n",
    "df_newdata_nyc2[npredictor_list_nyc] = df_newdata_nyc[npredictor_list_nyc].astype('float64')\n",
    "removed_historical_prices = df_newdata_nyc2.pop(DV)\n",
    "\n",
    "# Use the historical sample mean and historical sample standard deviation to standardize the made-up data\n",
    "df_newdata_nyc3 = df_newdata_nyc2.copy()\n",
    "df_newdata_nyc3[npredictor_list_nyc] = (df_newdata_nyc2[npredictor_list_nyc] - sample_mean_nyc[npredictor_list_nyc])/sample_stddev_nyc[npredictor_list_nyc]\n",
    "\n",
    "# Code the categorical variables in the made-up data \n",
    "df_newdata_nyc4 = pd.get_dummies(df_newdata_nyc3, prefix_sep='_')\n",
    "\n",
    "# Score the new data using the model carried by the model object clf_optimal \n",
    "predicted_standardized_price_nyc = clf_bestKNN2.predict(df_newdata_nyc4)\n",
    "\n",
    "# Convert the standardized predicted prices back to the original predicted prices using the historical sample mean and historical sample standard deviation\n",
    "predicted_price_nyc = predicted_standardized_price_nyc * sample_stddev_nyc[DV] + sample_mean_nyc[DV]\n",
    "\n",
    "# Print the predicted prices (in the original dollar amount) for the new data observations \n",
    "print(predicted_price_nyc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using only a naive \"averages\" model, the standardized error is  0.9999620464550201\n",
      "However, using KNN improves the standardized error to  0.9874570406027728\n",
      "\n",
      "Put differently, and readibly, the naive model is  1.0126638479833145 times worse than the KNN model.\n",
      "\n",
      "In terms of monetary value, the improvements the KNN model offers over the naive averages model, whether the correction is positive or negative, are:\n",
      "$ 8754719.55\n",
      "$ 8115904.16\n",
      "$ 8115904.16\n",
      "$ 4927480.42\n",
      "$ 2722719.33\n",
      "$ 359667.69\n",
      "$ 230773.97\n",
      "$ 230773.97\n",
      "$ 230773.97\n",
      "$ 90573.78\n",
      "$ 28388.21\n",
      "$ -48269.64\n",
      "$ -104801.97\n",
      "$ -131191.27\n",
      "$ -162080.54\n",
      "$ -193077.22\n",
      "$ -217339.09\n",
      "$ -221846.52\n",
      "$ -229060.05\n",
      "$ -260378.96\n",
      "$ -285253.19\n",
      "$ -375931.06\n",
      "$ -385654.62\n",
      "$ -402795.23\n",
      "$ -451232.13\n",
      "$ -463669.24\n"
     ]
    }
   ],
   "source": [
    "#Use a naive average to predict the future prices\n",
    "standardized_historical_prices = standardized_data_nyc[DV]\n",
    "prediction_by_average = df_nyc[DV].mean()\n",
    "standardized_prediction_by_average = standardized_historical_prices.mean()\n",
    "\n",
    "#Calculate ASE for the naive average model\n",
    "ASE_naive = sum((standardized_data_nyc[DV] - standardized_prediction_by_average)**2)/len(standardized_data_nyc[DV])\n",
    "print('Using only a naive \"averages\" model, the standardized error is ',ASE_naive)\n",
    "\n",
    "#Calculate ASE for the KNN model\n",
    "standardized_removed_historical_prices = (removed_historical_prices - df_nyc[DV].mean()) / df_nyc[DV].std()\n",
    "\n",
    "ASE_KNN = sum((standardized_removed_historical_prices - predicted_standardized_price_nyc )**2)/len(standardized_removed_historical_prices)\n",
    "print('However, using KNN improves the standardized error to ',ASE_KNN)\n",
    "\n",
    "#Compare the ratio of the improvement\n",
    "ASE_ratios = ASE_naive/ASE_KNN\n",
    "print('\\nPut differently, and readibly, the naive model is ',ASE_ratios,'times worse than the KNN model.')\n",
    "\n",
    "#Calculate monetary improvement of KNN model\n",
    "clean_list = []\n",
    "KNN_versus_Naive_absolute_dollar_difference = predicted_price_nyc - prediction_by_average\n",
    "print('\\nIn terms of monetary value, the improvements the KNN model offers over the naive averages model, whether the correction is positive or negative, are:')\n",
    "for i in KNN_versus_Naive_absolute_dollar_difference:\n",
    "    clean_list.append(round(i,2))\n",
    "for i in sorted(clean_list,reverse=True):\n",
    "    print('$',i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
